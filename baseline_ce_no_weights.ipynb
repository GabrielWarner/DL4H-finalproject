{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielWarner/DL4H-finalproject/blob/main/baseline_ce_no_weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "%pip install -q \"transformers==4.44.2\" \"datasets>=2.20.0\" \"evaluate==0.4.2\" pandas matplotlib tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNnYq_DMdARr",
        "outputId": "3ed6e00b-9b85-402b-ae3f-3dabf75528c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR  = \"/content/drive/MyDrive/DL4H_data/mimic\"\n",
        "CKPT_DIR  = \"/content/drive/MyDrive/DL4H_data/ckpt\"\n",
        "LOGS_DIR  = \"/content/drive/MyDrive/DL4H_data/logs\"\n",
        "FIGS_DIR  = \"/content/drive/MyDrive/DL4H_data/figs\"\n",
        "\n",
        "import os\n",
        "for p in [DATA_DIR, CKPT_DIR, LOGS_DIR, FIGS_DIR]:\n",
        "    os.makedirs(p, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "-U4gCT-EdBmk",
        "outputId": "e23957c3-9171-4556-f57c-4980fe2f5f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "mount failed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2725539756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mDATA_DIR\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/DL4H_data/mimic\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mCKPT_DIR\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/DL4H_data/ckpt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"HF_HOME\"] = \"/content/drive/MyDrive/DL4H_data/hf_cache\"\n",
        "os.makedirs(os.environ[\"HF_HOME\"], exist_ok=True)"
      ],
      "metadata": {
        "id": "QAOkPE2CdFK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ds = load_dataset(\"itsanmolgupta/mimic-cxr-dataset\")\n",
        "print(ds)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"report_id\": np.arange(len(ds[\"train\"])),\n",
        "    \"findings\": ds[\"train\"][\"findings\"],\n",
        "    \"impression\": ds[\"train\"][\"impression\"],\n",
        "})\n",
        "df[\"report_text\"] = (\n",
        "    df[\"impression\"].fillna(\"\").astype(str).str.strip() + \" \" +\n",
        "    df[\"findings\"].fillna(\"\").astype(str).str.strip()\n",
        ").str.strip()\n",
        "\n",
        "# drop empty reports\n",
        "df = df[df[\"report_text\"].str.len() > 0].reset_index(drop=True)\n",
        "print(\"Reports after filtering:\", len(df))\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "RHaelCH0dGyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(42)\n",
        "perm = rng.permutation(len(df))\n",
        "n = len(df)\n",
        "i_tr = int(0.8*n); i_va = int(0.9*n)\n",
        "\n",
        "df[\"split\"] = \"test\"\n",
        "df.loc[perm[:i_tr], \"split\"] = \"train\"\n",
        "df.loc[perm[i_tr:i_va], \"split\"] = \"val\"\n",
        "\n",
        "df[\"split\"].value_counts()"
      ],
      "metadata": {
        "id": "xkfRG4fZdMaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "def sent_tokenize(text: str):\n",
        "    parts = re.split(r'(?<=[\\.\\?\\!])\\s+|\\n+', text)\n",
        "    return [s.strip() for s in parts if s and s.strip()]\n",
        "\n",
        "ABN_TERMS = [\n",
        "    \"pneumonia\",\"consolidation\",\"edema\",\"effusion\",\"atelectasis\",\"pneumothorax\",\n",
        "    \"fracture\",\"opacity\",\"lesion\",\"mass\",\"enlarged\",\"cardiomegaly\",\"infiltrate\",\n",
        "    \"hemorrhage\",\"emphysema\",\"fibrosis\",\"collapse\",\"airspace\",\"air-fluid\",\"pleural\",\n",
        "    \"mediastinal widening\",\"hyperinflation\",\"interstitial\",\"ground-glass\"\n",
        "]\n",
        "NORM_PHRASES = [\n",
        "    \"no acute cardiopulmonary process\",\"no acute cardiopulmonary disease\",\n",
        "    \"no acute process\",\"no acute abnormality\",\"no acute findings\",\"no focal consolidation\",\n",
        "    \"no pleural effusion\",\"no pneumothorax\",\"heart size is normal\",\"lungs are clear\",\n",
        "    \"no acute osseous abnormality\"\n",
        "]\n",
        "UNCERTAIN_MARKERS = [\n",
        "    \"cannot exclude\",\"question of\",\"possible\",\"may represent\",\"suggest\",\"probable\",\n",
        "    \"likely\",\"suspicious for\",\" ?\",\" ? \"\n",
        "]\n",
        "\n",
        "abn_re  = re.compile(r\"\\b(\" + \"|\".join(re.escape(w) for w in ABN_TERMS) + r\")\\b\", re.I)\n",
        "norm_re = re.compile(\"|\".join(re.escape(p) for p in NORM_PHRASES), re.I)\n",
        "unc_re  = re.compile(\"|\".join(re.escape(p) for p in UNCERTAIN_MARKERS), re.I)\n",
        "\n",
        "def weak_label(s: str) -> str:\n",
        "    s = s.strip()\n",
        "    if not s:\n",
        "        return \"uncertain\"\n",
        "    has_abn  = bool(abn_re.search(s))\n",
        "    has_norm = bool(norm_re.search(s))\n",
        "    has_unc  = bool(unc_re.search(s))\n",
        "    if has_abn: return \"abnormal\"\n",
        "    if has_norm and not has_abn: return \"normal\"\n",
        "    return \"uncertain\""
      ],
      "metadata": {
        "id": "iMxKvCi5dO0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for idx, r in tqdm(df.iterrows(), total=len(df)):\n",
        "    sents = sent_tokenize(r[\"report_text\"])\n",
        "    for j, sent in enumerate(sents):\n",
        "        if len(sent) < 3:\n",
        "            continue\n",
        "        rows.append({\n",
        "            \"report_id\": int(r[\"report_id\"]),\n",
        "            \"sentence_id\": j,\n",
        "            \"text\": sent,\n",
        "            \"label\": weak_label(sent),\n",
        "            \"split\": r[\"split\"],\n",
        "        })\n",
        "\n",
        "sent_df = pd.DataFrame(rows)\n",
        "print(\"Total sentences:\", len(sent_df))\n",
        "sent_df.head(5)"
      ],
      "metadata": {
        "id": "WtdqKk1cdR5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dist(df):\n",
        "    return df[\"label\"].value_counts(normalize=True).round(3).to_dict()\n",
        "\n",
        "print(\"ALL:\", dist(sent_df))\n",
        "for sp in [\"train\",\"val\",\"test\"]:\n",
        "    print(sp, dist(sent_df[sent_df[\"split\"]==sp]))"
      ],
      "metadata": {
        "id": "JMDexTv0dVyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    out = (sent_df[sent_df[\"split\"]==split]\n",
        "           [[\"report_id\",\"sentence_id\",\"text\",\"label\"]]\n",
        "           .reset_index(drop=True))\n",
        "    out_path = f\"{DATA_DIR}/{split}.csv\"\n",
        "    out.to_csv(out_path, index=False)\n",
        "    print(split, len(out), \"->\", out_path)\n",
        "\n",
        "import pandas as pd\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    path = f\"{DATA_DIR}/{split}.csv\"\n",
        "    df_split = pd.read_csv(path)\n",
        "    df_split.sample(n=min(1000, len(df_split)), random_state=1).to_csv(\n",
        "        f\"{DATA_DIR}/{split}_mini.csv\", index=False\n",
        "    )\n",
        "print(\"Wrote mini splits.\")"
      ],
      "metadata": {
        "id": "BZazqkp6dYBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def label_dist(path):\n",
        "    df = pd.read_csv(path)\n",
        "    return {\"rows\": len(df), \"dist\": df[\"label\"].value_counts(normalize=True).round(3).to_dict()}\n",
        "\n",
        "print({\n",
        "    \"source\": \"HF itsanmolgupta/mimic-cxr-dataset + weak sentence labels (rule-based)\",\n",
        "    \"train\": label_dist(f\"{DATA_DIR}/train.csv\"),\n",
        "    \"val\":   label_dist(f\"{DATA_DIR}/val.csv\"),\n",
        "    \"test\":  label_dist(f\"{DATA_DIR}/test.csv\"),\n",
        "})"
      ],
      "metadata": {
        "id": "CGyhSmQGRlLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, platform\n",
        "print(\"CUDA:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available(): print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "import transformers, datasets, evaluate\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"evaluate:\", evaluate.__version__)\n",
        "print(\"Python:\", platform.python_version())\n",
        "print(\"CSV sizes:\",\n",
        "      {s: sum(1 for _ in open(f\"{DATA_DIR}/{s}.csv\"))-1 for s in [\"train\",\"val\",\"test\"]})"
      ],
      "metadata": {
        "id": "axF_4s0sdmyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- config ---\n",
        "LABELS = [\"normal\",\"abnormal\",\"uncertain\"]\n",
        "label2id = {l:i for i,l in enumerate(LABELS)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "MODEL_NAME = \"emilyalsentzer/Bio_ClinicalBERT\"\n",
        "MAX_LEN = 128\n",
        "BATCH_TRAIN = 32\n",
        "BATCH_EVAL  = 64\n",
        "LR = 2e-5\n",
        "EPOCHS = 3\n",
        "SEED = 42"
      ],
      "metadata": {
        "id": "cDPmrZxZSSMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, os\n",
        "def need(path):\n",
        "    assert os.path.exists(path), f\"Missing {path}\"\n",
        "    df = pd.read_csv(path)\n",
        "    req = {\"report_id\",\"sentence_id\",\"text\",\"label\"}\n",
        "    assert req.issubset(df.columns), f\"{path} must have columns {req}\"\n",
        "    return df\n",
        "\n",
        "train_df = need(f\"{DATA_DIR}/train.csv\")\n",
        "val_df   = need(f\"{DATA_DIR}/val.csv\")\n",
        "test_df  = need(f\"{DATA_DIR}/test.csv\")\n",
        "\n",
        "for d in (train_df, val_df, test_df):\n",
        "    d[\"labels\"] = d[\"label\"].map(label2id)"
      ],
      "metadata": {
        "id": "D1kb_0ENSWUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def to_ds(df): return Dataset.from_pandas(df[[\"text\",\"labels\"]].reset_index(drop=True))\n",
        "train_ds, val_ds, test_ds = map(to_ds, [train_df, val_df, test_df])\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tok(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
        "\n",
        "train_tok = train_ds.map(tokenize, batched=True).with_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
        "val_tok   = val_ds.map(tokenize,   batched=True).with_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
        "test_tok  = test_ds.map(tokenize,  batched=True).with_format(\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])"
      ],
      "metadata": {
        "id": "9XmN2tuVTFvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, evaluate\n",
        "metric_acc = evaluate.load(\"accuracy\")\n",
        "metric_f1  = evaluate.load(\"f1\")\n",
        "metric_auc = evaluate.load(\"roc_auc\",\"multiclass\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    out = {\n",
        "        \"accuracy\": metric_acc.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"f1_macro\": metric_f1.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "    }\n",
        "    try:\n",
        "        out[\"auc_ovr\"] = metric_auc.compute(\n",
        "            prediction_scores=logits, references=labels, multi_class=\"ovr\", average=\"macro\"\n",
        "        )[\"roc_auc\"]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return out"
      ],
      "metadata": {
        "id": "8e-YJ3cBT-Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, numpy as np, time, json\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, set_seed\n",
        "import os\n",
        "set_seed(SEED)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=3, id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "y = train_df[\"labels\"].to_numpy()\n",
        "counts = np.bincount(y, minlength=3)\n",
        "w = (1.0 / (counts + 1e-6)); w = w / w.sum() * 3.0\n",
        "class_weights = torch.tensor(w, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"class weights [normal, abnormal, uncertain]:\", class_weights.tolist())\n",
        "\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs); logits = outputs.get(\"logits\")\n",
        "        loss = torch.nn.functional.cross_entropy(logits, labels, weight=class_weights)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "run_name = f\"baseline_ce_{MODEL_NAME.split('/')[-1]}_{int(time.time())}\"\n",
        "out_dir  = f\"{CKPT_DIR}/{run_name}\"\n",
        "os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=out_dir,\n",
        "    per_device_train_batch_size=BATCH_TRAIN,\n",
        "    per_device_eval_batch_size=BATCH_EVAL,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    learning_rate=LR,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    seed=SEED,\n",
        "    fp16=True if torch.cuda.is_available() else False,\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    save_safetensors=False,\n",
        "    overwrite_output_dir=True,\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=val_tok,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "vrpj9LyeUEMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_out = trainer.train()\n",
        "test_metrics = trainer.evaluate(test_tok)\n",
        "test_metrics"
      ],
      "metadata": {
        "id": "kMEcGlJiUPSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, pandas as pd, matplotlib.pyplot as plt\n",
        "\n",
        "os.makedirs(FIGS_DIR, exist_ok=True)\n",
        "\n",
        "with open(os.path.join(out_dir, \"test_metrics.json\"), \"w\") as f:\n",
        "    json.dump(test_metrics, f, indent=2)\n",
        "pd.DataFrame([test_metrics]).to_csv(os.path.join(out_dir, \"test_metrics.csv\"), index=False)\n",
        "\n",
        "keys = [k for k in [\"eval_accuracy\",\"eval_f1_macro\"] if k in test_metrics]\n",
        "vals = [test_metrics[k] for k in keys]\n",
        "plt.figure(); plt.bar(keys, vals)\n",
        "for i,v in enumerate(vals): plt.text(i, v, f\"{v:.4f}\", ha=\"center\", va=\"bottom\")\n",
        "plt.title(\"Baseline (CE + class weights) ‚Äî Test\")\n",
        "fig_path = os.path.join(FIGS_DIR, f\"{os.path.basename(out_dir)}_metrics.png\")\n",
        "plt.savefig(fig_path, bbox_inches=\"tight\"); plt.show()\n",
        "\n",
        "{\"out_dir\": out_dir, \"fig\": fig_path}"
      ],
      "metadata": {
        "id": "-31R21I-aDgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "preds = trainer.predict(test_tok)\n",
        "y_true = preds.label_ids\n",
        "y_pred = np.argmax(preds.predictions, axis=-1)\n",
        "\n",
        "LABELS = [\"normal\",\"abnormal\",\"uncertain\"]\n",
        "print(classification_report(y_true, y_pred, target_names=LABELS, digits=3))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=range(len(LABELS)))\n",
        "cm_df = pd.DataFrame(cm, index=[f\"true_{l}\" for l in LABELS],\n",
        "                         columns=[f\"pred_{l}\" for l in LABELS])\n",
        "cm_df"
      ],
      "metadata": {
        "id": "2OjyzbUHsb9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, matplotlib.pyplot as plt\n",
        "\n",
        "logs = trainer.state.log_history\n",
        "\n",
        "train_epochs, train_losses = [], []\n",
        "val_epochs,   val_losses   = [], []\n",
        "\n",
        "for rec in logs:\n",
        "    if \"loss\" in rec and \"epoch\" in rec and \"eval_loss\" not in rec:\n",
        "        train_epochs.append(rec[\"epoch\"])\n",
        "        train_losses.append(rec[\"loss\"])\n",
        "    if \"eval_loss\" in rec and \"epoch\" in rec:\n",
        "        val_epochs.append(rec[\"epoch\"])\n",
        "        val_losses.append(rec[\"eval_loss\"])\n",
        "\n",
        "print(\"Train loss points:\", len(train_losses))\n",
        "print(\"Val loss points:\", len(val_losses))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(train_epochs, train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_epochs,   val_losses,   label=\"Val Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss\")\n",
        "plt.legend()\n",
        "\n",
        "# üëâ save BEFORE or AFTER show, but in the same cell/figure\n",
        "loss_fig_path = os.path.join(FIGS_DIR, \"baseline_loss_curve.png\")\n",
        "plt.savefig(loss_fig_path, bbox_inches=\"tight\")\n",
        "plt.show()\n",
        "\n",
        "loss_fig_path"
      ],
      "metadata": {
        "id": "rVNCokb-3tvX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}